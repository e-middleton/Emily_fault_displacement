{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a2403f",
   "metadata": {},
   "source": [
    "# CMI Code for Meshing and Clipping Subduction Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e488592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np # Numerical analysis\n",
    "import gmsh # Creation of fault models\n",
    "import meshio # Interaction between fault model files and Python\n",
    "import matplotlib.pyplot as plt # Visualize \n",
    "from pyproj import Proj\n",
    "import pyproj\n",
    "import h5py\n",
    "import scipy #for interpolation\n",
    "from scipy.interpolate import NearestNDInterpolator \n",
    "from geopandas import geoseries\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af480fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some basic coordinate transformation functions\n",
    "GEOID = pyproj.Geod(ellps=\"WGS84\")\n",
    "KM2M = 1.0e3\n",
    "RADIUS_EARTH = np.float64((GEOID.a + GEOID.b) / 2)\n",
    "\n",
    "def sph2cart(lon, lat, radius):\n",
    "    lon_rad = np.deg2rad(lon)\n",
    "    lat_rad = np.deg2rad(lat)\n",
    "    x = radius * np.cos(lat_rad) * np.cos(lon_rad)\n",
    "    y = radius * np.cos(lat_rad) * np.sin(lon_rad)\n",
    "    z = radius * np.sin(lat_rad)\n",
    "    return x, y, z\n",
    "\n",
    "def cart2sph(x, y, z):\n",
    "    azimuth = np.arctan2(y, x)\n",
    "    elevation = np.arctan2(z, np.sqrt(x ** 2 + y ** 2))\n",
    "    r = np.sqrt(x ** 2 + y ** 2 + z ** 2)\n",
    "    return azimuth, elevation, r\n",
    "\n",
    "def wrap2360(lon):\n",
    "    lon[np.where(lon < 0.0)] += 360.0\n",
    "    return lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09472c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in source fault\n",
    "# filename = \"cascadia.msh\"\n",
    "filename = \"japan.msh\"\n",
    "mesh = dict()\n",
    "meshobj = meshio.read(filename)\n",
    "mesh[\"file_name\"] = filename\n",
    "mesh[\"points\"] = meshobj.points\n",
    "mesh[\"verts\"] = meshio.CellBlock(\"triangle\", meshobj.get_cells_type(\"triangle\")).data\n",
    "ntri = len(mesh[\"verts\"])\n",
    "\n",
    "# Expand mesh coordinates\n",
    "mesh[\"lon1\"] = mesh[\"points\"][mesh[\"verts\"][:, 0], 0]\n",
    "mesh[\"lon2\"] = mesh[\"points\"][mesh[\"verts\"][:, 1], 0]\n",
    "mesh[\"lon3\"] = mesh[\"points\"][mesh[\"verts\"][:, 2], 0]\n",
    "mesh[\"lat1\"] = mesh[\"points\"][mesh[\"verts\"][:, 0], 1]\n",
    "mesh[\"lat2\"] = mesh[\"points\"][mesh[\"verts\"][:, 1], 1]\n",
    "mesh[\"lat3\"] = mesh[\"points\"][mesh[\"verts\"][:, 2], 1]\n",
    "mesh[\"dep1\"] = mesh[\"points\"][mesh[\"verts\"][:, 0], 2]\n",
    "mesh[\"dep2\"] = mesh[\"points\"][mesh[\"verts\"][:, 1], 2]\n",
    "mesh[\"dep3\"] = mesh[\"points\"][mesh[\"verts\"][:, 2], 2]\n",
    "mesh[\"centroids\"] = np.mean(mesh[\"points\"][mesh[\"verts\"], :], axis=1)\n",
    "\n",
    "# Cartesian coordinates in meters\n",
    "mesh[\"x1\"], mesh[\"y1\"], mesh[\"z1\"] = sph2cart(\n",
    "    mesh[\"lon1\"],\n",
    "    mesh[\"lat1\"],\n",
    "    RADIUS_EARTH + KM2M * mesh[\"dep1\"],\n",
    ")\n",
    "mesh[\"x2\"], mesh[\"y2\"], mesh[\"z2\"] = sph2cart(\n",
    "    mesh[\"lon2\"],\n",
    "    mesh[\"lat2\"],\n",
    "    RADIUS_EARTH + KM2M * mesh[\"dep2\"],\n",
    ")\n",
    "mesh[\"x3\"], mesh[\"y3\"], mesh[\"z3\"] = sph2cart(\n",
    "    mesh[\"lon3\"],\n",
    "    mesh[\"lat3\"],\n",
    "    RADIUS_EARTH + KM2M * mesh[\"dep3\"],\n",
    ")\n",
    "# Cartesian triangle centroids\n",
    "mesh[\"x_centroid\"] = (mesh[\"x1\"] + mesh[\"x2\"] + mesh[\"x3\"]) / 3.0\n",
    "mesh[\"y_centroid\"] = (mesh[\"y1\"] + mesh[\"y2\"] + mesh[\"y3\"]) / 3.0\n",
    "mesh[\"z_centroid\"] = (mesh[\"z1\"] + mesh[\"z2\"] + mesh[\"z3\"]) / 3.0\n",
    "\n",
    "# Cross products for orientations\n",
    "tri_leg1 = np.transpose([np.deg2rad(mesh[\"lon2\"] - mesh[\"lon1\"]), np.deg2rad(mesh[\"lat2\"] - mesh[\"lat1\"]), (1 + KM2M * mesh[\"dep2\"] / RADIUS_EARTH) - (1 + KM2M * mesh[\"dep1\"] / RADIUS_EARTH)])\n",
    "tri_leg2 = np.transpose([np.deg2rad(mesh[\"lon3\"] - mesh[\"lon1\"]), np.deg2rad(mesh[\"lat3\"] - mesh[\"lat1\"]), (1 + KM2M * mesh[\"dep3\"] / RADIUS_EARTH) - (1 + KM2M * mesh[\"dep1\"] / RADIUS_EARTH)])\n",
    "mesh[\"nv\"] = np.cross(tri_leg1, tri_leg2)\n",
    "azimuth, elevation, r = cart2sph(mesh[\"nv\"][:, 0], mesh[\"nv\"][:, 1], mesh[\"nv\"][:, 2])\n",
    "mesh[\"strike\"] = wrap2360(-np.rad2deg(azimuth))\n",
    "mesh[\"dip\"] = 90 - np.rad2deg(elevation)\n",
    "mesh[\"dip_flag\"] = mesh[\"dip\"] != 90\n",
    "\n",
    "# Set up grid where vertical displacement will be calculated\n",
    "\n",
    "# Cascadia range\n",
    "# xs = np.linspace(237, 240, 100)\n",
    "# ys = np.linspace(40, 50, 100)\n",
    "\n",
    "# Hokkaido range\n",
    "xs = np.linspace(140, 144, 200)\n",
    "ys = np.linspace(41, 44, 200)\n",
    "\n",
    "# Reshape grid\n",
    "obsx, obsy = np.meshgrid(xs, ys)\n",
    "pts = np.array([obsx, obsy, 0 * obsy]).reshape((3, -1)).T.copy()\n",
    "\n",
    "# Convert the fault and grid coordinates to Cartesian\n",
    "\n",
    "# Set up transformation\n",
    "lon_corr = 1\n",
    "# Check longitude convention of mesh\n",
    "if np.max(xs) > 180:\n",
    "    lon_corr = 0\n",
    "\n",
    "utmzone=int(32700-(np.sign(np.mean(ys))+1)/2 * 100+np.floor((lon_corr*180 + np.mean(xs))/6) + 1)\n",
    "target_crs = 'epsg:'+str(utmzone) # Coordinate system of the file\n",
    "source_crs = 'epsg:4326' # Global lat-lon coordinate system\n",
    "latlon_to_utm = pyproj.Transformer.from_crs(source_crs, target_crs)\n",
    "\n",
    "# Convert coordinates\n",
    "faultxy = np.array(latlon_to_utm.transform(mesh[\"points\"][:, 1], mesh[\"points\"][:, 0])).T/1e3\n",
    "gridxy = np.array(latlon_to_utm.transform(pts[:, 1], pts[:, 0])).T/1e3 \n",
    "\n",
    "cart_fault_pts = np.zeros_like(mesh[\"points\"])\n",
    "cart_fault_pts[:, 0:2] = faultxy\n",
    "cart_fault_pts[:, 2] = mesh[\"points\"][:, 2]\n",
    "cart_grid_pts = np.zeros_like(pts)\n",
    "cart_grid_pts[:, 0:2] = gridxy\n",
    "cart_grid_pts[:, 2] = pts[:, 2]\n",
    "\n",
    "#good place to calc area, property of every single element, in sq km, so multiply by 1,000,000 so it is in terms of meters (1000 m x 1000 m)\n",
    "cart_leg1 = cart_fault_pts[mesh[\"verts\"][:,1]] - cart_fault_pts[mesh[\"verts\"][:,0]]\n",
    "cart_leg2 = cart_fault_pts[mesh[\"verts\"][:,2]] - cart_fault_pts[mesh[\"verts\"][:,1]]\n",
    "mesh[\"cart_nv\"] = np.cross(cart_leg1, cart_leg2)\n",
    "\n",
    "mesh[\"area\"] = ((np.linalg.norm(mesh[\"cart_nv\"],axis=1))/2) * (1e6)\n",
    "# Plot the source fault\n",
    "\n",
    "# Setting up axis limits\n",
    "xmin = np.mean(mesh[\"points\"][:, 0]) - 3*np.std(mesh[\"points\"][:, 0])\n",
    "xmax = np.mean(mesh[\"points\"][:, 0]) + 3*np.std(mesh[\"points\"][:, 0])\n",
    "ymin = np.mean(mesh[\"points\"][:, 1]) - 3*np.std(mesh[\"points\"][:, 1])\n",
    "ymax = np.mean(mesh[\"points\"][:, 1]) + 3*np.std(mesh[\"points\"][:, 1])\n",
    "# Read in coastline file\n",
    "coast = pd.read_csv(\"coastline.csv\")\n",
    "# Define the figure and its axis\n",
    "fig, ax = plt.subplots()\n",
    "# Draw the fault\n",
    "ax.triplot(mesh[\"points\"][:, 0], mesh[\"points\"][:, 1], mesh[\"verts\"], linewidth=0.5)\n",
    "# Add grid points\n",
    "ax.plot(pts[:, 0], pts[:, 1], '.r')\n",
    "# Add coastline\n",
    "ax.plot(coast.lon+360*(1-lon_corr), coast.lat, color=\"gray\", linewidth=0.5)\n",
    "ax.set(xlim=(xmin, xmax), ylim=(ymin, ymax), aspect='equal')\n",
    "plt.show()\n",
    "\n",
    "# Make another plot, showing fault and grid in Cartesian coordinates\n",
    "fig, ax = plt.subplots()\n",
    "ax.triplot(cart_fault_pts[:,0], cart_fault_pts[:, 1], mesh[\"verts\"], linewidth=0.5)\n",
    "ax.plot(cart_grid_pts[:, 0], cart_grid_pts[:, 1], '.r')\n",
    "ax.set(aspect=\"equal\")\n",
    "plt.show()\n",
    "\n",
    "# Show elements colored by strike\n",
    "fig, ax = plt.subplots()\n",
    "# Draw the fault\n",
    "ax.tripcolor(mesh[\"points\"][:, 0], mesh[\"points\"][:, 1], mesh[\"verts\"], facecolors=mesh[\"strike\"])\n",
    "# Add coastline\n",
    "ax.plot(coast.lon+360*(1-lon_corr), coast.lat, color=\"gray\", linewidth=0.5)\n",
    "ax.set(xlim=(xmin-1, xmax+1), ylim=(ymin, ymax), aspect='equal')\n",
    "plt.show()\n",
    "\n",
    "# #Show elements colored by depth\n",
    "# fig, ax = plt.subplots()\n",
    "# fo = ax.tripcolor(mesh[\"points\"][:, 0], mesh[\"points\"][:, 1], mesh[\"verts\"], facecolors=mesh[\"centroids\"][:,2])\n",
    "# plt.colorbar(fo) #uses info from plotted object to create scale\n",
    "# # Add coastline\n",
    "# ax.plot(coast.lon+360*(1-lon_corr), coast.lat, color=\"gray\", linewidth=0.5)\n",
    "# ax.title.set_text(\"Fault Colored By Depth (km)\")\n",
    "# ax.set(xlim=(xmin, xmax), ylim=(ymin, ymax), aspect='equal')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6089b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful functions for determining points along triangle legs\n",
    "\n",
    "def direction_vector(p1, p2):\n",
    "    dir_vec = [(p2[0] - p1[0]), (p2[1] - p1[1]), (p2[2] - p1[2])]\n",
    "    return dir_vec\n",
    "\n",
    "\n",
    "# a point P on a line segment will be P = t * direction_vector + end_point\n",
    "# where t is a scalar amount, here, determined by the known plane_depth\n",
    "# this is done for each element of point P, (x,y,z)\n",
    "def point_grab(vector, t, start):\n",
    "    point = [(t*vector[0] + start[0]), (t*vector[1] + start[1]), (t*vector[2] + start[2])]\n",
    "    return point\n",
    "\n",
    "# for each point, the desired depth value\n",
    "# is the same as plane_depth\n",
    "# so z is always known, and we can create the scalar quantity\n",
    "# for the rest of the points based upon it\n",
    "# plane_depth = z1 + t(z2 - z1)\n",
    "# t = (plane_depth - z1) / (z2 - z1)\n",
    "def scalar(p1, p2, depth):\n",
    "    t = (depth - p1[2]) / (p2[2] - p1[2])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96f047",
   "metadata": {},
   "source": [
    "#### Determine points along the depth contour based on triangle legs\n",
    "\n",
    "Each triangle element of the mesh has three vertices, [A,B,C]. After sorting the triangles to determine which elements span the depth contour,\n",
    "you then need to determine which two legs of the triangle cross that plane.\n",
    "\n",
    "There are 6 possible combinations of [A,B,C] where at least one is above and at least one is below the plane.\n",
    "The combinations are as follows (where T=below and F=above the plane)\n",
    "[TTF], [TFT], [TFF], [FTT], [FTF], [FFT]\n",
    "The other two combinations [TTT] and [FFF] are either entirely above or entirely below the plane depth, \n",
    "and therefore not possible for the given set of triangle elements after sorting.\n",
    "\n",
    "After this, the points along the depth contour are calculated, one for each triangle leg.\n",
    "\n",
    "#### Example point calculation along depth contour:\n",
    "\n",
    "For three triangle vertices: [A,B,C]\n",
    "Where each vertex consists of [*lon*, *lat*, *dep*]\n",
    "\n",
    "\n",
    "To find point P, along line segment **AB** at a depth of 60 km:\n",
    "\n",
    "Each element in point P can be found using an endpoint of the line segment, and adding a scalar quantity (t) of the direction vector.\n",
    "\n",
    "+ *lon*P = *lon***A** + (t * **AB**[0])\n",
    "\n",
    "+ *lat*P = *lat***A** + (t * **AB**[1])\n",
    "\n",
    "+ *dep*P = *dep***A** + (t * **AB**[2])\n",
    "\n",
    "direction vector **AB** = [(*lon***B** - *lon***A**), (*lat***B** - *lat***A**), (*dep***B** - *dep***A**)]\n",
    "\n",
    "But we know that the third element, depth, will always be 60 for our point along the depth contour.\n",
    "\n",
    "P[2] = 60 = *dep***A** + (t * **AB**[2])\n",
    "\n",
    "60 = *dep***A** + (t * [*dep***B** - *dep***A**])\n",
    "\n",
    "t = (60 - *dep***A**) / (*dep***B** - *dep***A**)\n",
    "\n",
    "So because we can find a value for scalar t, we can determine the other values of elements in point P, and thus, point P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08709e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create depth contour points using triangle elements spanning the CMI depth\n",
    "\n",
    "# depth of the CMI\n",
    "plane_depth = 60\n",
    "\n",
    "# triangle node values and empty list\n",
    "# each row is a triangle element [lon1, lat1, dep1, lon2, lat2, dep2, lon3, lat3, dep3]\n",
    "nodes = np.empty((mesh[\"lon1\"].size, 9))\n",
    "nodes[:,0] = mesh[\"lon1\"]\n",
    "nodes[:,1] = mesh[\"lat1\"]\n",
    "nodes[:,2] = abs(mesh[\"dep1\"])\n",
    "nodes[:,3] = mesh[\"lon2\"]\n",
    "nodes[:,4] = mesh[\"lat2\"]\n",
    "nodes[:,5] = abs(mesh[\"dep2\"])\n",
    "nodes[:,6] = mesh[\"lon3\"]\n",
    "nodes[:,7] = mesh[\"lat3\"]\n",
    "nodes[:,8] = abs(mesh[\"dep3\"])\n",
    "\n",
    "sort_by = [] # python implements lists as dynamic arrays.\n",
    "# for each row (triangle element), check if the depths span the contour needed\n",
    "# if the depths span the contour, that means the triangle legs cross 60 km depth\n",
    "# and a point on two legs can be included in the contour \n",
    "\n",
    "for i in range(np.size(nodes, 0)):\n",
    "    node_depth = [nodes[i,2], nodes[i,5], nodes[i,8]] # access the depth values of a triangle element\n",
    "    if (max(node_depth) > plane_depth > min(node_depth)):\n",
    "        sort_by.append(True)\n",
    "    else:\n",
    "        sort_by.append(False)\n",
    "\n",
    "bool_mask = np.array(sort_by) \n",
    "\n",
    "# construct an array where each row is a triangle (lon1, lat1, dep1, lon2, lat2, dep2, lon3, lat3, dep3)\n",
    "# which spans the depth contour, sorted by the boolean mask made earlier\n",
    "tri_elem = np.empty((bool_mask.sum(), 9)) #sum is adding up True=1 False=0\n",
    "tri_elem[::] = nodes[::][bool_mask] # grab triangle elements based on the depth spanning criteria\n",
    "\n",
    "\n",
    "# there are six combinations of point arrangements, but only 3 unique combinations of line segments ac, ab, bc\n",
    "# array for points along the depth contour (including duplicates), each element will have two points\n",
    "depth_all = np.empty(((2*np.size(tri_elem, 0)), 3)) \n",
    "m = 0 # row number of the current point, initialized outside of loop\n",
    "\n",
    "# determine line segments crossing plane, determine point coordinates on the line segment\n",
    "# add the points to the array\n",
    "for j in range(np.size(tri_elem, 0)):\n",
    "    a = tri_elem[j,[0,1,2]] #node a\n",
    "    b = tri_elem[j,[3,4,5]] #node b\n",
    "    c = tri_elem[j,[6,7,8]] #node c\n",
    "\n",
    "    # create direction vectors for line segments\n",
    "    # all three are created to avoid code clutter in if-statements\n",
    "    ab = direction_vector(a, b)\n",
    "    ac = direction_vector(a, c)\n",
    "    bc = direction_vector(b, c)\n",
    "\n",
    "    # determine the combination of nodes above and below the CMI plane\n",
    "    combo = [bool(a[2]>plane_depth), bool(b[2]>plane_depth), bool(c[2]>plane_depth)]\n",
    "\n",
    "    # ab, ac are the triangle legs when a is alone above or below the line\n",
    "    if ((combo==[True, False, False]) or (combo==[False,True,True])):\n",
    "        t1 = scalar(a, b, plane_depth)\n",
    "        t2 = scalar(a, c, plane_depth)\n",
    "\n",
    "        # each point along the depth contour can be found using an end point, plus a scalar quantity along a direction vector\n",
    "        p1 = point_grab(ab, t1, a) \n",
    "        p2 = point_grab(ac, t2, a)\n",
    "\n",
    "        depth_all[m,0] = p1[0] ; depth_all[m,1] = p1[1] ; depth_all[m,2] = p1[2]\n",
    "        m+=1 # increment the row number for each point added\n",
    "        depth_all[m,0] = p2[0] ; depth_all[m,1] = p2[1] ; depth_all[m,2] = p2[2]\n",
    "        m+=1 # increment row\n",
    "\n",
    "    # ab, bc when b is alone above or below the line\n",
    "    elif ((combo==[True,False,True]) or (combo==[False,True,False])):\n",
    "        t1 = scalar(a, b, plane_depth)\n",
    "        t2 = scalar(b, c, plane_depth)\n",
    "\n",
    "        p1 = point_grab(ab, t1, a)\n",
    "        p2 = point_grab(bc, t2, b)\n",
    "\n",
    "        depth_all[m,0] = p1[0] ; depth_all[m,1] = p1[1] ; depth_all[m,2] = p1[2]\n",
    "        m+=1 # increment the row number for each point added\n",
    "        depth_all[m,0] = p2[0] ; depth_all[m,1] = p2[1] ; depth_all[m,2] = p2[2]\n",
    "        m+=1 # increment row\n",
    "\n",
    "    # only remaining line segment combination is [ac, bc], where vertex C is isolated above/below\n",
    "    else:\n",
    "        t1 = scalar(a, c, plane_depth)\n",
    "        t2 = scalar(b, c, plane_depth)\n",
    "\n",
    "        #each of the three components of point1 are endpoint, plus a scalar quantity of the direction vector\n",
    "        p1 = point_grab(ac, t1, a)\n",
    "        p2 = point_grab(bc, t2, b) # the z component will always be 60 km or plane_depth, including the equation helps clarify other indicies\n",
    "\n",
    "        depth_all[m,0] = p1[0] ; depth_all[m,1] = p1[1] ; depth_all[m,2] = p1[2]\n",
    "        m+=1 # increment the row number for each point added\n",
    "        depth_all[m,0] = p2[0] ; depth_all[m,1] = p2[1] ; depth_all[m,2] = p2[2]\n",
    "        m+=1 # increment row\n",
    "\n",
    "\n",
    "# triangles share legs, so points are repeated unnecessarily, this takes only the unique rows in the 2D array\n",
    "df = pd.DataFrame(depth_all, columns=[\"lon\", \"lat\", \"dep\"])\n",
    "depth_contour = df.drop_duplicates(subset=[\"lon\"])\n",
    "depth_contour = np.array(df.drop_duplicates(subset=\"lat\"))\n",
    "\n",
    "# using pandas not numpy, because numpy will sort the columns, but that shuffles lon, lat pairs apart\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(depth_contour[:,0], depth_contour[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121997a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Mesh the CMI based upon lower depth extent of afterslip ~60km\n",
    "\n",
    "#sort points by increasing latitude\n",
    "indicies = np.argsort( depth_contour[:,1] )\n",
    "depth_contour = depth_contour[indicies]\n",
    "\n",
    "# separately add on the corners of the CMI\n",
    "min_lon = 137 # minimum longitude value for corner\n",
    "min_lat = 34\n",
    "max_lat = np.max(depth_contour[:,1]+0.5) # maximum latitude for corner\n",
    "\n",
    "# corner points starting from lower left and moving counterclockwise\n",
    "corner_points = np.array([[min_lon, min_lat, plane_depth], [depth_contour[0,0], min_lat, plane_depth], [min_lon, max_lat, plane_depth], [np.max(depth_contour[:,0]), max_lat, plane_depth]])\n",
    "\n",
    "# total points along the perimiter of the CMI mesh\n",
    "mesh_edge = np.concatenate((depth_contour, corner_points))\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(mesh_edge[:, 0], mesh_edge[:, 1])\n",
    "# plt.show()\n",
    "\n",
    "cx = mesh_edge[:,0]\n",
    "cy = mesh_edge[:,1]\n",
    "cz = -1*mesh_edge[:,2] # depth is negative\n",
    "\n",
    "## BEGIN GMSH\n",
    "\n",
    "char_len = 1 # smaller is good for degrees\n",
    "n_points = np.shape(depth_contour)[0] # number of depth contour points\n",
    "num_surf = np.shape(depth_contour)[0]\n",
    "num_lines = np.shape(mesh_edge)[0] #num lines is the same as the total number of points\n",
    "\n",
    "if gmsh.isInitialized() == 0:\n",
    "    gmsh.initialize()\n",
    "gmsh.option.setNumber(\"General.Verbosity\", 0)\n",
    "gmsh.clear()\n",
    "\n",
    "# Define points\n",
    "gmsh.model.geo.addPoint(cx[-4], cy[-4], cz[-4], char_len, 0) #lower left corner because corner points were added last in the mesh_points\n",
    "gmsh.model.geo.addPoint(cx[-3], cy[-3], cz[-3], char_len, 1)\n",
    "for j in range(int(n_points)): # depth contour points\n",
    "    gmsh.model.geo.addPoint(cx[j], cy[j], cz[j], char_len, j+2) \n",
    "\n",
    "gmsh.model.geo.addPoint(cx[-1], cy[-1], cz[-1], char_len, j+3) #upper right corner\n",
    "gmsh.model.geo.addPoint(cx[-2], cy[-2], cz[-2], char_len, j+4) #upper left corner\n",
    "\n",
    "# add lines between the points to complete the perimiter\n",
    "for i in range(int(num_lines-1)):\n",
    "    gmsh.model.geo.addLine(i, i+1, i)\n",
    "gmsh.model.geo.addLine(i+1, 0, i+1) #complete the loop\n",
    "\n",
    "gmsh.model.geo.synchronize()\n",
    "\n",
    "# define curve loop counterclockwise\n",
    "gmsh.model.geo.addCurveLoop(list(range(0, i+2)), 1)\n",
    "\n",
    "gmsh.model.geo.addPlaneSurface([1], 1)\n",
    "\n",
    "# Finish writing geo attributes\n",
    "gmsh.model.geo.synchronize()\n",
    "\n",
    "gmsh.write('horiz' + '.geo_unrolled')\n",
    "\n",
    "# Generate mesh\n",
    "gmsh.model.mesh.generate(2) #meshed in spherical because the depth being in km isn't as important when it's flat\n",
    "\n",
    "gmsh.write('horiz' + '.msh')\n",
    "gmsh.finalize()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99953c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and parse mesh\n",
    "horiz = dict()\n",
    "# information about the CMI mesh is read in, and stored in a dictionary just like for fault mesh earlier\n",
    "horizobj = meshio.read(\"horiz.msh\") \n",
    "horiz[\"points\"] = horizobj.points\n",
    "horiz[\"verts\"] = meshio.CellBlock(\"triangle\", horizobj.get_cells_type(\"triangle\")).data\n",
    "\n",
    "keep_el = np.ones(len(horiz[\"verts\"])).astype(bool)\n",
    "\n",
    "for i in range(len(horiz[\"verts\"])):\n",
    "    tri_test = np.shape(np.unique(horiz[\"points\"][horiz[\"verts\"][i,:],:],axis=0))[0]\n",
    "    if tri_test != 3:\n",
    "        keep_el[i] = False\n",
    "\n",
    "horiz[\"verts\"] = horiz[\"verts\"][keep_el,:]\n",
    "\n",
    "# Expand mesh coordinates\n",
    "horiz[\"lon1\"] = horiz[\"points\"][horiz[\"verts\"][:, 0], 0]\n",
    "horiz[\"lon2\"] = horiz[\"points\"][horiz[\"verts\"][:, 1], 0]\n",
    "horiz[\"lon3\"] = horiz[\"points\"][horiz[\"verts\"][:, 2], 0]\n",
    "horiz[\"lat1\"] = horiz[\"points\"][horiz[\"verts\"][:, 0], 1]\n",
    "horiz[\"lat2\"] = horiz[\"points\"][horiz[\"verts\"][:, 1], 1]\n",
    "horiz[\"lat3\"] = horiz[\"points\"][horiz[\"verts\"][:, 2], 1]\n",
    "horiz[\"dep1\"] = horiz[\"points\"][horiz[\"verts\"][:, 0], 2]\n",
    "horiz[\"dep2\"] = horiz[\"points\"][horiz[\"verts\"][:, 1], 2]\n",
    "horiz[\"dep3\"] = horiz[\"points\"][horiz[\"verts\"][:, 2], 2]\n",
    "horiz[\"centroids\"] = np.mean(horiz[\"points\"][horiz[\"verts\"], :], axis=1)\n",
    "\n",
    "# Cartesian coordinates in meters\n",
    "horiz[\"x1\"], horiz[\"y1\"], horiz[\"z1\"] = sph2cart(\n",
    "    horiz[\"lon1\"],\n",
    "    horiz[\"lat1\"],\n",
    "    RADIUS_EARTH + KM2M * horiz[\"dep1\"],\n",
    ")\n",
    "horiz[\"x2\"], horiz[\"y2\"], horiz[\"z2\"] = sph2cart(\n",
    "    horiz[\"lon2\"],\n",
    "    horiz[\"lat2\"],\n",
    "    RADIUS_EARTH + KM2M * horiz[\"dep2\"],\n",
    ")\n",
    "horiz[\"x3\"], horiz[\"y3\"], horiz[\"z3\"] = sph2cart(\n",
    "    horiz[\"lon3\"],\n",
    "    horiz[\"lat3\"],\n",
    "    RADIUS_EARTH + KM2M * horiz[\"dep3\"],\n",
    ")\n",
    "# Cartesian triangle centroids\n",
    "horiz[\"x_centroid\"] = (horiz[\"x1\"] + horiz[\"x2\"] + horiz[\"x3\"]) / 3.0\n",
    "horiz[\"y_centroid\"] = (horiz[\"y1\"] + horiz[\"y2\"] + horiz[\"y3\"]) / 3.0\n",
    "horiz[\"z_centroid\"] = (horiz[\"z1\"] + horiz[\"z2\"] + horiz[\"z3\"]) / 3.0\n",
    "\n",
    "# Cross products for orientations\n",
    "tri_leg1 = np.transpose([np.deg2rad(horiz[\"lon2\"] - horiz[\"lon1\"]), np.deg2rad(horiz[\"lat2\"] - horiz[\"lat1\"]), (1 + KM2M * horiz[\"dep2\"] / RADIUS_EARTH) - (1 + KM2M * horiz[\"dep1\"] / RADIUS_EARTH)])\n",
    "tri_leg2 = np.transpose([np.deg2rad(horiz[\"lon3\"] - horiz[\"lon1\"]), np.deg2rad(horiz[\"lat3\"] - horiz[\"lat1\"]), (1 + KM2M * horiz[\"dep3\"] / RADIUS_EARTH) - (1 + KM2M * horiz[\"dep1\"] / RADIUS_EARTH)])\n",
    "horiz[\"nv\"] = np.cross(tri_leg1, tri_leg2)\n",
    "azimuth, elevation, r = cart2sph(horiz[\"nv\"][:, 0], horiz[\"nv\"][:, 1], horiz[\"nv\"][:, 2])\n",
    "horiz[\"strike\"] = wrap2360(-np.rad2deg(azimuth))\n",
    "horiz[\"dip\"] = 90 - np.rad2deg(elevation)\n",
    "horiz[\"dip_flag\"] = horiz[\"dip\"] != 90\n",
    "\n",
    "# Draw the fault \n",
    "fig, ax = plt.subplots()\n",
    "ax.triplot(horiz[\"points\"][:, 0], horiz[\"points\"][:, 1], horiz[\"verts\"], linewidth=0.25)\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4803b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice off elements of subduction zone that have centroid depths greater than the CMI depth contour depth\n",
    "\n",
    "bool_mask # indices of elements that cross the depth contour\n",
    "\n",
    "keep = mesh[\"centroids\"][:,2] > -1*plane_depth\n",
    "print(np.sum(keep))\n",
    "keep_vals = mesh[\"verts\"][keep]\n",
    "\n",
    "\n",
    "tri_elem # lon1, lat1, dep1 ... nodes of elements spanning the depth contour\n",
    "changed_points = mesh[\"verts\"][bool_mask]\n",
    "centroid_vals = mesh[\"centroids\"][bool_mask]\n",
    "print(np.max(centroid_vals), np.min(centroid_vals))\n",
    "\n",
    "if 0:\n",
    "    plt.close('all')\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].tripcolor(mesh[\"points\"][:, 0], mesh[\"points\"][:, 1], mesh[\"verts\"], linewidth=0.25, facecolors=bool_mask)\n",
    "    ax[0].set_aspect(\"equal\")\n",
    "\n",
    "    ax[1].triplot(mesh[\"points\"][:,0], mesh[\"points\"][:,1], keep_vals, linewidth=0.25)\n",
    "    ax[1].scatter(depth_contour[:,0], depth_contour[:,1], s=1, marker='*', linewidths=1, edgecolors='r')\n",
    "    ax[1].set_aspect(\"equal\")\n",
    "    plt.show()\n",
    "\n",
    "short_mesh = dict()\n",
    "short_mesh[\"file_name\"] = mesh[\"file_name\"]\n",
    "short_mesh[\"points\"] = mesh[\"points\"]\n",
    "short_mesh[\"verts\"] = mesh[\"verts\"][keep]\n",
    "short_mesh[\"lon1\"] = mesh[\"lon1\"][keep]\n",
    "short_mesh[\"lon2\"] = mesh[\"lon2\"][keep]\n",
    "short_mesh[\"lon3\"] = mesh[\"lon3\"][keep]\n",
    "short_mesh[\"lat1\"] = mesh[\"lat1\"][keep]\n",
    "short_mesh[\"lat2\"] = mesh[\"lat2\"][keep]\n",
    "short_mesh[\"lat3\"] = mesh[\"lat3\"][keep]\n",
    "short_mesh[\"dep1\"] = mesh[\"dep1\"][keep]\n",
    "short_mesh[\"dep2\"] = mesh[\"dep2\"][keep]\n",
    "short_mesh[\"dep3\"] = mesh[\"dep3\"][keep]\n",
    "short_mesh[\"centroids\"] = mesh[\"centroids\"][keep]\n",
    "short_mesh[\"x1\"] = mesh[\"x1\"][keep]\n",
    "short_mesh[\"y1\"] = mesh[\"y1\"][keep]\n",
    "short_mesh[\"z1\"] = mesh[\"z1\"][keep]\n",
    "short_mesh[\"x2\"] = mesh[\"x2\"][keep]\n",
    "short_mesh[\"y2\"] = mesh[\"y2\"][keep]\n",
    "short_mesh[\"z2\"] = mesh[\"z2\"][keep]\n",
    "short_mesh[\"x3\"] = mesh[\"x3\"][keep]\n",
    "short_mesh[\"y3\"] = mesh[\"y3\"][keep]\n",
    "short_mesh[\"z3\"] = mesh[\"z3\"][keep]\n",
    "short_mesh[\"x_centroid\"] = mesh[\"x_centroid\"][keep]\n",
    "short_mesh[\"y_centroid\"] = mesh[\"y_centroid\"][keep]\n",
    "short_mesh[\"z_centroid\"] = mesh[\"z_centroid\"][keep]\n",
    "short_mesh[\"nv\"] = mesh[\"nv\"][keep]\n",
    "short_mesh[\"strike\"] = mesh[\"strike\"][keep]\n",
    "short_mesh[\"dip\"] = mesh[\"dip\"][keep]\n",
    "short_mesh[\"dip_flag\"] = mesh[\"dip_flag\"][keep]\n",
    "short_mesh[\"cart_nv\"] = mesh[\"cart_nv\"][keep]\n",
    "short_mesh[\"area\"] = mesh[\"area\"][keep]\n",
    "\n",
    "# replace elements coordinates along the bottom edge with the top coordinates of the CMI mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d683460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 6 possibilities for mesh plane intersection of the triangles\n",
    "# given 3 nodes [a,b,c], where T is above and F is below the clipping plane, \n",
    "# [TFF], [TTF], [TFT], [FTF], [FFT], [FTT]\n",
    "# these possibilities are numbered 1 through 6\n",
    "# if 1: keep node a, and add points along ab and ac calculated from the depth contour\n",
    "# if 2: [a, bc, ac] [a, b, ac]\n",
    "# if 3: [a, bc, ab] [a, c, bc]\n",
    "# if 4: [b, ab, bc]\n",
    "# if 5: [c, ac, bc]\n",
    "# if 6: [b, ac, ab] [b, c, ac]\n",
    "\n",
    "\n",
    "# add new points calculated along line segments to the old points\n",
    "df = pd.DataFrame(depth_all, columns=[\"lon\", \"lat\", \"dep\"])\n",
    "depth_contour = df.drop_duplicates(subset=[\"lon\"])\n",
    "depth_contour = np.array(depth_contour.drop_duplicates(subset=\"lat\")) # order of elements determined by order of tri_elem, not sorted\n",
    "\n",
    "num_old = len(mesh[\"points\"][:,0])\n",
    "new_points = np.empty(((num_old + len(depth_contour[:,0])), 3))\n",
    "\n",
    "# add the old points as well as the new points to a shared array, contains points deeper than needed for now\n",
    "new_points[0:num_old, 0] = mesh[\"points\"][:, 0]\n",
    "new_points[0:num_old, 1] = mesh[\"points\"][:, 1]\n",
    "new_points[0:num_old, 2] = mesh[\"points\"][:, 2]\n",
    "new_points[num_old:, 0] = depth_contour[:,0]\n",
    "new_points[num_old:, 1] = depth_contour[:,1]\n",
    "new_points[num_old:, 2] = depth_contour[:,2] \n",
    "\n",
    "points_beg_idx = num_old # beginning of the new points calculated for depth contour\n",
    "\n",
    "# determine the combination possibility that each element is\n",
    "combo_list = np.empty((len(tri_elem[:,0]), 3))\n",
    "num_extra = 0\n",
    "\n",
    "for j in range(np.size(tri_elem, 0)):\n",
    "    a = tri_elem[j,[0,1,2]] #node a\n",
    "    b = tri_elem[j,[3,4,5]] #node b\n",
    "    c = tri_elem[j,[6,7,8]] #node c\n",
    "\n",
    "    # determine the combination of nodes above and below the CMI plane\n",
    "    combo = [bool(a[2]>plane_depth), bool(b[2]>plane_depth), bool(c[2]>plane_depth)]\n",
    "    combo_list[j,0] = combo[0]\n",
    "    combo_list[j,1] = combo[1]\n",
    "    combo_list[j,2] = combo[2]\n",
    "\n",
    "    if sum(combo)==2: # if more than two nodes are above the CMI depth, the remaining shape is a quadrilateral and two triangles must be created from it\n",
    "        num_extra += 1\n",
    "\n",
    "# create array of new triangle elements\n",
    "new_tri_elem = np.empty(((len(tri_elem[:,0])+num_extra), 9)) # as many as previously plus the new ones\n",
    "point_count = 0\n",
    "\n",
    "for i in range(len(combo_list[:,0])):\n",
    "    temp_list = [combo_list[i,0], combo_list[i,1], combo_list[i,2]]\n",
    "\n",
    "    if temp_list==[True,False,False]:\n",
    "        new_tri_elem[i, [0,1,2]] = tri_elem[i,[0,1,2]] # keep node a\n",
    "        new_tri_elem[i, [3,4,5]] = depth_all[point_count, [0,1,2]] ; point_count += 1 # add ab\n",
    "        new_tri_elem[i, [6,7,8]] = depth_all[point_count, [0,1,2]]\n",
    "\n",
    "\n",
    "# new centroids, normal vectors, cartesian coordinates, and areas will need to be calculated for these elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [\"station_ID\", 'lon', 'lat', 'east_vel', 'north_vel', 'up_vel']\n",
    "gps = pd.read_table(\"./cumulative_disp.txt\", sep='\\s+', header=None, names=colnames)\n",
    "\n",
    "# Place stations into single array\n",
    "# lat, lon, dep, but dep is always zero because they're on the ground\n",
    "# reshape(3, -1) means put it into 3 rows and as many columns as data points\n",
    "# then T makes it 3 columns, and as many rows as data points\n",
    "obsv = np.array([gps.lon, gps.lat, 0*gps.lat]).reshape((3, -1)).T.copy()\n",
    "\n",
    "vec_scale = 2500\n",
    "\n",
    "plot_vectors = True\n",
    "plt.close('all')\n",
    "if plot_vectors:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.quiver(gps.lon, gps.lat, gps.east_vel, gps.north_vel, scale=vec_scale)\n",
    "    ax.axis(\"equal\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/anitamiddleton/Documents/python/celeri')\n",
    "\n",
    "import celeri \n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Force meshes into dataclass, using existing fields\n",
    "class Mesh:\n",
    "    def __init__(self, d=None):\n",
    "        if d is not None:\n",
    "            for key, value in d.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "# List of classes\n",
    "meshes = [Mesh(short_mesh), Mesh(horiz)]\n",
    "\n",
    "# Quick config class\n",
    "@dataclass\n",
    "class Config:\n",
    "    material_lambda = 30000000000\n",
    "    material_mu = 30000000000\n",
    "config = Config()\n",
    "\n",
    "# Define indices for meshes in arrays, where each meshes triangle elements begin\n",
    "n_tri = np.zeros(len(meshes), dtype=int)\n",
    "for i in range(len(meshes)):\n",
    "    n_tri[i] = len(meshes[i].lon1)\n",
    "tri_end_idx = np.cumsum(n_tri) # the last triangle index, the sum of all triangle elem in both meshes\n",
    "tri_beg_idx = [0, tri_end_idx[0]] # list of indexes, the beginning of the fault mesh elem, beginning of the cmi mesh elem\n",
    "total_n_tri = tri_end_idx[-1] \n",
    "# gets the last element of the summation that makes up total triangles, here, the number of tri elem in the CMI\n",
    "\n",
    "# Allocate space for slip-to-displacement array\n",
    "disp_mat = np.zeros((3*len(gps.lon), 3*np.sum(n_tri)))\n",
    "# Allocate space for slip-to-displacement array\n",
    "smoothing_mat = np.zeros((3*np.sum(n_tri), 3*np.sum(n_tri)))\n",
    "\n",
    "# For each mesh, fill in disp_mat with the values and not just zeros\n",
    "for mesh_idx in range(len(meshes)):\n",
    "    # Calculate slip to displacement partials, using geographic coordinates\n",
    "    disp_mat[:, 3*tri_beg_idx[mesh_idx]:3*tri_end_idx[mesh_idx]] = celeri.spatial.get_tde_to_velocities_single_mesh(meshes, gps, config, mesh_idx)\n",
    "    # Get smoothing operator\n",
    "\n",
    "    # Indices of shared sides in this mesh\n",
    "    share = celeri.spatial.get_shared_sides(meshes[mesh_idx].verts)\n",
    "    # Distances between centroids of shared elements\n",
    "    tri_shared_sides_distances = celeri.spatial.get_tri_shared_sides_distances(\n",
    "            share,\n",
    "            meshes[mesh_idx].x_centroid,\n",
    "            meshes[mesh_idx].y_centroid,\n",
    "            meshes[mesh_idx].z_centroid,\n",
    "        )\n",
    "    # Distance-scaled smoothing matrix\n",
    "    smat = celeri.spatial.get_tri_smoothing_matrix(\n",
    "            share, tri_shared_sides_distances\n",
    "        )\n",
    "    # Insert sparse matrix into full array\n",
    "    smoothing_mat[3*tri_beg_idx[mesh_idx]:3*tri_end_idx[mesh_idx], 3*tri_beg_idx[mesh_idx]:3*tri_end_idx[mesh_idx]] = smat.toarray()\n",
    "    # Get smoothing operator\n",
    "\n",
    "    # Indices of shared sides in this mesh\n",
    "    # find which triangles share sides with which triangles, because in a group, \n",
    "    # general idea: one triangle gets 3, other three around it get -1, end result after summation is smooth\n",
    "    share = celeri.spatial.get_shared_sides(meshes[mesh_idx].verts)\n",
    "    # Distances between centroids of shared elements\n",
    "    tri_shared_sides_distances = celeri.spatial.get_tri_shared_sides_distances(\n",
    "            share,\n",
    "            meshes[mesh_idx].x_centroid,\n",
    "            meshes[mesh_idx].y_centroid,\n",
    "            meshes[mesh_idx].z_centroid,\n",
    "        )\n",
    "    # Distance-scaled smoothing matrix\n",
    "    smat = celeri.spatial.get_tri_smoothing_matrix(\n",
    "            share, tri_shared_sides_distances\n",
    "        )\n",
    "    # Insert sparse matrix into full array\n",
    "    smoothing_mat[3*tri_beg_idx[mesh_idx]:3*tri_end_idx[mesh_idx], 3*tri_beg_idx[mesh_idx]:3*tri_end_idx[mesh_idx]] = smat.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a33d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if elem are line elem instead of triangle \n",
    "\n",
    "bad_cols = np.isnan(disp_mat[0,:])\n",
    "bad_el = int(np.where(bad_cols)[0][0]/3)\n",
    "\n",
    "thing = bad_el - tri_beg_idx[1]\n",
    "print(np.shape(np.unique(horiz[\"points\"][horiz[\"verts\"][thing,:],:],axis=0))[0])\n",
    "print(horiz[\"verts\"][thing,:])\n",
    "\n",
    "# Draw the fault \n",
    "fig, ax = plt.subplots()\n",
    "ax.triplot(horiz[\"points\"][:, 0], horiz[\"points\"][:, 1], horiz[\"verts\"], linewidth=0.25)\n",
    "ax.plot(horiz[\"centroids\"][thing,0], horiz[\"centroids\"][thing,1], \"*r\")\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble matrices\n",
    "\n",
    "assembled_mat = np.vstack([disp_mat, smoothing_mat]) # stick constraint array as 3rd argument\n",
    "\n",
    "# List of smoothing weights to test\n",
    "smooths = [1e-16, 1e-6, 1e-2, 1e-1, 1, 10, 100, 1000, 1e6, 1e9, 1e16]\n",
    "\n",
    "# Select a smoothing weight and apply to meshes\n",
    "smoothing_weight = smooths[8]\n",
    "if np.size(smoothing_weight) != len(meshes):\n",
    "    smoothing_weight = smoothing_weight*np.ones(len(meshes)) \n",
    "\n",
    "# Assemble weighting vector\n",
    "# Allocate space for data vector\n",
    "data_vector = np.zeros((np.shape(assembled_mat)[0], 1)) # by default, the rows corresponding to constraint array are initialized as zeros\n",
    "# Vector of displacements\n",
    "disp_array = np.array([gps.east_vel, gps.north_vel, gps.up_vel]).reshape((3,-1)).T.copy()\n",
    "data_vector[0:np.size(disp_array)] = disp_array.flatten().reshape(-1,1)\n",
    "\n",
    "# Start with unit uncertainties \n",
    "# this puts the smoothing weight for the fault mesh and cmi mesh, and leaves gps stations as 1\n",
    "weights = np.ones((np.shape(assembled_mat)[0], 1)) # might want to update when adding slip constraint\n",
    "for mesh_idx in range(len(meshes)):\n",
    "    weights[np.size(disp_array)+ 3*tri_beg_idx[mesh_idx]:3*tri_end_idx[mesh_idx]] = smoothing_weight[mesh_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model covariance\n",
    "cov = np.linalg.inv(assembled_mat.T * weights.T @ assembled_mat) \n",
    "\n",
    "# Estimate slip using pre-calculated covariance\n",
    "est_slip = cov @ assembled_mat.T * weights.T @ data_vector \n",
    "# Predict displacement at stations\n",
    "pred_disp = disp_mat.dot(est_slip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73201689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for visualizing\n",
    "vec_scale = 2500\n",
    "plt.close('all')\n",
    "end_idx = 3*tri_end_idx[0] #end of fault elem beginning of cmi elem\n",
    "\n",
    "max_mag = np.abs(np.max(est_slip[1::3]))\n",
    "max_mag_f = np.abs(np.max(est_slip[1:end_idx:3]))\n",
    "max_mag_h = np.abs(np.max(est_slip[end_idx::3]))/100\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "rso = ax[0].tripcolor(short_mesh[\"points\"][:,0], short_mesh[\"points\"][:,1], short_mesh[\"verts\"], \n",
    "                      facecolors=(est_slip[1:end_idx:3]).flatten(), vmin=-max_mag_f, vmax=max_mag_f)\n",
    "ax[0].tripcolor(horiz[\"points\"][:,0], horiz[\"points\"][:,1], horiz[\"verts\"], facecolors=(est_slip[end_idx::3]/100).flatten())\n",
    "cbar1 = fig.colorbar(rso, ax=ax[0], orientation='horizontal')\n",
    "cbar1.set_label(\"Slip (m)\")\n",
    "ax[0].set(xlim=(xmin-2, xmax), ylim=(ymin, ymax), aspect='equal')\n",
    "ax[0].title.set_text(\"Fault Slip (East)\") #graph 1\n",
    "ax[0].set_ylabel(\"Latitude\")\n",
    "ax[0].set_xlabel(\"Longitude\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "rso = ax[1].tripcolor(horiz[\"points\"][:,0], horiz[\"points\"][:,1], horiz[\"verts\"], facecolors=(est_slip[end_idx+1::3]/100).flatten(), vmin=-max_mag_h, vmax=max_mag_h)\n",
    "cbar1 = fig.colorbar(rso, ax=ax[1], orientation='horizontal')\n",
    "cbar1.set_label(\"Slip (m)\")\n",
    "#ax[1].quiver(gps.lon, gps.lat, pred_disp[0::3], pred_disp[1::3], scale=vec_scale, color='r', label=\"predicted\")\n",
    "#ax[1].quiver(gps.lon, gps.lat, gps.east_vel, gps.north_vel, scale=vec_scale, color='k', label='observed')\n",
    "ax[1].set(xlim=(xmin-2, xmax), ylim=(ymin, ymax), aspect='equal')\n",
    "ax[1].title.set_text(\"CMI Slip (East)\") #graph 1\n",
    "ax[1].set_ylabel(\"Latitude\")\n",
    "ax[1].set_xlabel(\"Longitude\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.quiver(gps.lon, gps.lat, gps.east_vel, gps.north_vel, scale=vec_scale, color='k', label='observed')\n",
    "ax.quiver(gps.lon, gps.lat, pred_disp[0::3], pred_disp[1::3], scale=vec_scale, color='r', label=\"predicted\")\n",
    "#ax.quiver(gps.lon, gps.lat, data_vector[0:1497:3], data_vector[1:1497:3], scale=vec_scale, color='b')\n",
    "ax.axis(\"equal\")\n",
    "plt.title(\"Predicted Displacements (cm)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
